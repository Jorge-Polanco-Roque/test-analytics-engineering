name: DBT CI/CD Pipeline

# Pipeline CI/CD para DBT
# Ejecuta en PRs (tests) y en merge a main (deploy a prod)

on:
  # Ejecutar en pull requests
  pull_request:
    branches:
      - main
      - master
      - develop
    paths:
      - 'dbt_project/**'
      - '.github/workflows/**'

  # Ejecutar en push a main (despliegue a producci√≥n)
  push:
    branches:
      - main
      - master
    paths:
      - 'dbt_project/**'

  # Permitir ejecuci√≥n manual
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - prod

  # Ejecuci√≥n programada (opcional - desactivado por defecto)
  # schedule:
  #   - cron: '0 6 * * *'  # Diario a las 6 AM UTC

# Variables de entorno globales
env:
  PYTHON_VERSION: '3.11'
  DBT_VERSION: '1.7.9'

# Permisos necesarios
permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  # ==========================================================================
  # JOB 1: VALIDACI√ìN DE C√ìDIGO
  # ==========================================================================
  validate:
    name: Validate Code Quality
    runs-on: ubuntu-latest

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: üì¶ Install dependencies
        run: |
          pip install --upgrade pip
          pip install sqlfluff==2.3.5
          pip install dbt-core==${{ env.DBT_VERSION }}
          pip install dbt-bigquery==${{ env.DBT_VERSION }}

      - name: üîß Create DBT profiles.yml
        run: |
          mkdir -p ~/.dbt
          cat > ~/.dbt/profiles.yml << EOF
          bank_marketing:
            target: dev
            outputs:
              dev:
                type: bigquery
                method: service-account
                project: ${{ secrets.DBT_GCP_PROJECT }}
                dataset: bank_marketing_dev
                location: US
                threads: 4
                timeout_seconds: 300
                priority: interactive
                keyfile: /tmp/gcp-key.json
              staging:
                type: bigquery
                method: service-account
                project: ${{ secrets.DBT_GCP_PROJECT_STAGING }}
                dataset: bank_marketing_staging
                location: US
                threads: 2
                timeout_seconds: 300
                priority: interactive
                keyfile: /tmp/gcp-key.json
              prod:
                type: bigquery
                method: service-account
                project: ${{ secrets.DBT_GCP_PROJECT_PROD }}
                dataset: bank_marketing_prod
                location: US
                threads: 1
                timeout_seconds: 300
                priority: interactive
                keyfile: /tmp/gcp-key.json
          EOF

      - name: üîê Create GCP credentials file
        run: |
          echo '${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}' > /tmp/gcp-key.json

      - name: üîé Verify profiles.yml was created
        run: |
          echo "Checking if profiles.yml exists..."
          ls -la ~/.dbt/
          echo "---"
          echo "Content of profiles.yml:"
          cat ~/.dbt/profiles.yml
          echo "---"
          echo "Verifying keyfile exists:"
          ls -la /tmp/gcp-key.json

      - name: üîç Lint SQL with SQLFluff
        run: |
          cd dbt_project
          sqlfluff lint models/ \
            --dialect bigquery \
            --exclude-rules L034,L036 \
            --format github-annotation
        continue-on-error: true

      - name: üìö Install DBT packages
        run: |
          cd dbt_project
          dbt deps || true

      - name: ‚úÖ Parse DBT project
        run: |
          cd dbt_project
          dbt parse || true
        env:
          DBT_GCP_PROJECT: ${{ secrets.DBT_GCP_PROJECT }}

      - name: üìù Check for compilation errors
        run: |
          cd dbt_project
          dbt compile || true
        env:
          DBT_GCP_PROJECT: ${{ secrets.DBT_GCP_PROJECT }}

  # ==========================================================================
  # JOB 2: EJECUTAR TESTS EN STAGING
  # ==========================================================================
  test:
    name: Run DBT Tests
    runs-on: ubuntu-latest
    needs: validate
    if: github.event_name == 'pull_request'

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: üì¶ Install DBT and dependencies
        run: |
          pip install --upgrade pip
          pip install dbt-core==${{ env.DBT_VERSION }}
          pip install dbt-bigquery==${{ env.DBT_VERSION }}

      - name: üîß Create DBT profiles.yml
        run: |
          mkdir -p ~/.dbt
          cat > ~/.dbt/profiles.yml << EOF
          bank_marketing:
            target: dev
            outputs:
              dev:
                type: bigquery
                method: service-account
                project: ${{ secrets.DBT_GCP_PROJECT }}
                dataset: bank_marketing_dev
                location: US
                threads: 4
                timeout_seconds: 300
                priority: interactive
                keyfile: /tmp/gcp-key.json
              staging:
                type: bigquery
                method: service-account
                project: ${{ secrets.DBT_GCP_PROJECT_STAGING }}
                dataset: bank_marketing_staging
                location: US
                threads: 2
                timeout_seconds: 300
                priority: interactive
                keyfile: /tmp/gcp-key.json
              prod:
                type: bigquery
                method: service-account
                project: ${{ secrets.DBT_GCP_PROJECT_PROD }}
                dataset: bank_marketing_prod
                location: US
                threads: 1
                timeout_seconds: 300
                priority: interactive
                keyfile: /tmp/gcp-key.json
          EOF

      - name: üîê Create GCP credentials file
        run: |
          echo '${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}' > /tmp/gcp-key.json

      - name: ‚òÅÔ∏è Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          service_account_key: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
          project_id: ${{ secrets.DBT_GCP_PROJECT }}

      - name: üìö Install DBT packages
        run: |
          cd dbt_project
          dbt deps || true

      - name: üèóÔ∏è Run DBT models (staging)
        run: |
          cd dbt_project
          dbt run \
            --target staging \
            --full-refresh
        env:
          DBT_GCP_PROJECT: ${{ secrets.DBT_GCP_PROJECT_STAGING }}

      - name: üß™ Run DBT tests
        run: |
          cd dbt_project
          dbt test \
            --target staging \
            --store-failures
        env:
          DBT_GCP_PROJECT: ${{ secrets.DBT_GCP_PROJECT_STAGING }}

      - name: üìä Generate test results summary
        if: always()
        run: |
          cd dbt_project
          dbt test --target staging || true
          echo "## DBT Test Results" >> $GITHUB_STEP_SUMMARY
          echo "Tests completed. Check logs for details." >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # JOB 3: DESPLIEGUE A PRODUCCI√ìN
  # ==========================================================================
  deploy-prod:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: validate
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master')
    environment:
      name: production
      url: https://console.cloud.google.com/bigquery

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: üì¶ Install DBT and dependencies
        run: |
          pip install --upgrade pip
          pip install dbt-core==${{ env.DBT_VERSION }}
          pip install dbt-bigquery==${{ env.DBT_VERSION }}

      - name: üîß Create DBT profiles.yml
        run: |
          mkdir -p ~/.dbt
          cat > ~/.dbt/profiles.yml << EOF
          bank_marketing:
            target: dev
            outputs:
              dev:
                type: bigquery
                method: service-account
                project: ${{ secrets.DBT_GCP_PROJECT }}
                dataset: bank_marketing_dev
                location: US
                threads: 4
                timeout_seconds: 300
                priority: interactive
                keyfile: /tmp/gcp-key.json
              staging:
                type: bigquery
                method: service-account
                project: ${{ secrets.DBT_GCP_PROJECT_STAGING }}
                dataset: bank_marketing_staging
                location: US
                threads: 2
                timeout_seconds: 300
                priority: interactive
                keyfile: /tmp/gcp-key.json
              prod:
                type: bigquery
                method: service-account
                project: ${{ secrets.DBT_GCP_PROJECT_PROD }}
                dataset: bank_marketing_prod
                location: US
                threads: 1
                timeout_seconds: 300
                priority: interactive
                keyfile: /tmp/gcp-key.json
          EOF

      - name: üîê Create GCP credentials file
        run: |
          echo '${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}' > /tmp/gcp-key.json

      - name: ‚òÅÔ∏è Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          service_account_key: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
          project_id: ${{ secrets.DBT_GCP_PROJECT }}

      - name: üìö Install DBT packages
        run: |
          cd dbt_project
          dbt deps || true

      - name: üîç Check source freshness
        run: |
          cd dbt_project
          dbt source freshness \
            --target prod
        env:
          DBT_GCP_PROJECT: ${{ secrets.DBT_GCP_PROJECT_PROD }}
        continue-on-error: true

      - name: üèóÔ∏è Run DBT models (production)
        run: |
          cd dbt_project
          dbt run \
            --target prod \
            --full-refresh
        env:
          DBT_GCP_PROJECT: ${{ secrets.DBT_GCP_PROJECT_PROD }}

      - name: üß™ Run DBT tests (production)
        run: |
          cd dbt_project
          dbt test \
            --target prod \
            --store-failures
        env:
          DBT_GCP_PROJECT: ${{ secrets.DBT_GCP_PROJECT_PROD }}

      - name: üìñ Generate documentation
        run: |
          cd dbt_project
          dbt docs generate \
            --target prod
        env:
          DBT_GCP_PROJECT: ${{ secrets.DBT_GCP_PROJECT_PROD }}

      - name: üì§ Upload documentation artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dbt-docs
          path: dbt_project/target/
          retention-days: 30

      - name: ‚úÖ Deployment summary
        run: |
          echo "## üöÄ Production Deployment Successful" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Environment**: Production" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit**: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Actor**: ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp**: $(date -u)" >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # JOB 4: AUDITOR√çA DE CALIDAD DE DATOS
  # ==========================================================================
  data-quality-audit:
    name: Data Quality Audit
    runs-on: ubuntu-latest
    needs: deploy-prod
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master')

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: üì¶ Install dependencies
        run: |
          pip install --upgrade pip
          pip install dbt-core==${{ env.DBT_VERSION }}
          pip install dbt-bigquery==${{ env.DBT_VERSION }}
          pip install pandas
          pip install google-cloud-bigquery

      - name: üîß Create DBT profiles.yml
        run: |
          mkdir -p ~/.dbt
          cat > ~/.dbt/profiles.yml << EOF
          bank_marketing:
            target: dev
            outputs:
              dev:
                type: bigquery
                method: service-account
                project: ${{ secrets.DBT_GCP_PROJECT }}
                dataset: bank_marketing_dev
                location: US
                threads: 4
                timeout_seconds: 300
                priority: interactive
                keyfile: /tmp/gcp-key.json
              staging:
                type: bigquery
                method: service-account
                project: ${{ secrets.DBT_GCP_PROJECT_STAGING }}
                dataset: bank_marketing_staging
                location: US
                threads: 2
                timeout_seconds: 300
                priority: interactive
                keyfile: /tmp/gcp-key.json
              prod:
                type: bigquery
                method: service-account
                project: ${{ secrets.DBT_GCP_PROJECT_PROD }}
                dataset: bank_marketing_prod
                location: US
                threads: 1
                timeout_seconds: 300
                priority: interactive
                keyfile: /tmp/gcp-key.json
          EOF

      - name: üîê Create GCP credentials file
        run: |
          echo '${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}' > /tmp/gcp-key.json

      - name: ‚òÅÔ∏è Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          service_account_key: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
          project_id: ${{ secrets.DBT_GCP_PROJECT }}

      - name: üîç Run data quality checks
        run: |
          cd dbt_project

          echo "Running comprehensive data quality audit..."

          # Ejecutar tests con store-failures
          dbt test --target prod --store-failures || true

          # Generar reporte de calidad
          echo "## üìä Data Quality Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "All data quality tests have been executed." >> $GITHUB_STEP_SUMMARY
          echo "Check test_results schema in BigQuery for failed records." >> $GITHUB_STEP_SUMMARY
        env:
          DBT_GCP_PROJECT: ${{ secrets.DBT_GCP_PROJECT_PROD }}

  # ==========================================================================
  # JOB 5: NOTIFICACIONES (OPCIONAL)
  # ==========================================================================
  notify:
    name: Send Notifications
    runs-on: ubuntu-latest
    needs: [deploy-prod, data-quality-audit]
    if: always() && (github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'))

    steps:
      - name: üìß Notify on Success
        if: needs.deploy-prod.result == 'success' && needs.data-quality-audit.result == 'success'
        run: |
          echo "‚úÖ Pipeline completed successfully!"
          # Aqu√≠ puedes agregar notificaciones a Slack, Email, etc.
          # Ejemplo con Slack:
          # curl -X POST -H 'Content-type: application/json' \
          #   --data '{"text":"DBT deployment successful!"}' \
          #   ${{ secrets.SLACK_WEBHOOK_URL }}

      - name: ‚ö†Ô∏è Notify on Failure
        if: needs.deploy-prod.result == 'failure' || needs.data-quality-audit.result == 'failure'
        run: |
          echo "‚ùå Pipeline failed!"
          # Enviar notificaci√≥n de fallo

# ============================================================================
# CONFIGURACI√ìN DE SECRETS REQUERIDOS EN GITHUB
# ============================================================================
#
# Navega a: Settings ‚Üí Secrets and variables ‚Üí Actions ‚Üí New repository secret
#
# Secrets requeridos:
#
# 1. GCP_SERVICE_ACCOUNT_KEY
#    - JSON key de la service account de GCP
#    - Debe tener permisos de BigQuery Data Editor y Job User
#
# 2. DBT_GCP_PROJECT
#    - ID del proyecto GCP para development/testing
#    - Ejemplo: "my-company-data-dev"
#
# 3. DBT_GCP_PROJECT_STAGING
#    - ID del proyecto GCP para staging
#    - Ejemplo: "my-company-data-staging"
#
# 4. DBT_GCP_PROJECT_PROD
#    - ID del proyecto GCP para producci√≥n
#    - Ejemplo: "my-company-data-prod"
#
# 5. SLACK_WEBHOOK_URL (opcional)
#    - URL del webhook de Slack para notificaciones
#
# ============================================================================
